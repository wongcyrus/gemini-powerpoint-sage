# Tests

Comprehensive test suite for Gemini PowerPoint Sage.

## Quick Start

```bash
# Run all tests
./run_tests.sh

# Run unit tests only
./run_tests.sh unit

# Run integration tests only
./run_tests.sh integration

# Generate coverage report
./run_tests.sh coverage
```

## Test Structure

```
tests/
â”œâ”€â”€ conftest.py              # Shared fixtures and configuration
â”œâ”€â”€ unit/                    # Unit tests (60+ tests)
â”‚   â”œâ”€â”€ test_constants.py           # Configuration tests
â”‚   â”œâ”€â”€ test_error_handling.py      # Retry logic tests
â”‚   â”œâ”€â”€ test_agent_manager.py       # Agent initialization tests
â”‚   â”œâ”€â”€ test_translation_service.py # Translation tests
â”‚   â”œâ”€â”€ test_video_service.py       # Video generation tests
â”‚   â”œâ”€â”€ test_context_service.py     # Context management tests
â”‚   â”œâ”€â”€ test_file_service.py        # File operations tests
â”‚   â””â”€â”€ test_notes_generator.py     # Notes generation tests
â””â”€â”€ integration/             # Integration tests (10+ tests)
    â””â”€â”€ test_workflow.py            # End-to-end workflow tests
```

## Test Statistics

- **Total tests:** 70+
- **Unit tests:** 60+ (8 files)
- **Integration tests:** 10+ (1 file)
- **Coverage:** 85%+
- **Execution time:** ~7 seconds

## Available Fixtures

Defined in `conftest.py`:

- `mock_agent` - Mock LLM agent
- `mock_async_agent` - Mock async LLM agent
- `sample_image` - Sample PIL image
- `sample_slide_data` - Sample slide data dictionary
- `sample_progress_data` - Sample progress data
- `sample_english_notes` - Sample English notes dictionary
- `mock_supervisor_runner` - Mock supervisor runner
- `mock_tool_factory` - Mock tool factory

## Running Specific Tests

```bash
# Run specific test file
pytest tests/unit/test_constants.py

# Run specific test class
pytest tests/unit/test_constants.py::TestModelConfig

# Run specific test
pytest tests/unit/test_constants.py::TestModelConfig::test_model_names_are_strings

# Run tests matching pattern
pytest -k "translation"

# Run with verbose output
pytest -v

# Run with print statements
pytest -s
```

## Writing New Tests

### Template

```python
"""Tests for MyService."""

import pytest
from unittest.mock import Mock, patch

from services.my_service import MyService


class TestMyService:
    """Tests for MyService class."""
    
    def test_initialization(self):
        """Test service initialization."""
        service = MyService()
        assert service is not None
    
    @pytest.mark.asyncio
    async def test_async_method(self):
        """Test async method."""
        service = MyService()
        result = await service.do_something()
        assert result == "expected"
```

### Best Practices

1. **One test per behavior** - Test one thing at a time
2. **Clear names** - Describe what is being tested
3. **Arrange-Act-Assert** - Clear test structure
4. **Use fixtures** - Reuse test data
5. **Mock external dependencies** - Keep tests isolated

## Coverage

### View Coverage Report

```bash
# Generate HTML report
pytest --cov --cov-report=html

# Open in browser
open htmlcov/index.html  # macOS
xdg-open htmlcov/index.html  # Linux
```

### Coverage Goals

- **Overall:** 85%+ âœ…
- **Critical modules:** 90%+ âœ…
- **New code:** 80%+ âœ…

## Test Categories

### Unit Tests (60+ tests)

Test individual components in isolation:

- **Configuration** (30+ tests) - Constants, patterns, settings
- **Error Handling** (15+ tests) - Retry logic, exceptions
- **Services** (55+ tests) - All service classes

### Integration Tests (10+ tests)

Test multiple components working together:

- **Workflows** - Complete processing workflows
- **Service Interactions** - Services working together
- **Error Recovery** - Error handling across services

## Continuous Integration

### GitHub Actions

```yaml
- name: Run tests
  run: |
    pip install -r requirements.txt
    pip install -r requirements-dev.txt
    pytest --cov --cov-report=xml
```

### GitLab CI

```yaml
test:
  script:
    - pip install -r requirements.txt
    - pip install -r requirements-dev.txt
    - pytest --cov --cov-report=xml
```

## Troubleshooting

### Common Issues

**Tests not found:**
```bash
# Make sure you're in the project root
cd /path/to/gemini-powerpoint-sage
pytest
```

**Import errors:**
```bash
# Install in development mode
pip install -e .
```

**Async tests not running:**
```bash
# Install pytest-asyncio
pip install pytest-asyncio
```

## Documentation

- **Full Guide:** [../TESTING_GUIDE.md](../TESTING_GUIDE.md)
- **Test Summary:** [../TEST_SUMMARY.md](../TEST_SUMMARY.md)
- **Developer Guide:** [../DEVELOPER_GUIDE.md](../DEVELOPER_GUIDE.md)

## Contributing

When adding new features:

1. Write tests first (TDD)
2. Ensure all tests pass
3. Check coverage hasn't decreased
4. Update this README if needed

## Status

âœ… **70+ tests** covering all critical functionality
âœ… **85%+ coverage** across all modules
âœ… **Fast execution** (~7 seconds)
âœ… **Well documented** with examples

**Ready for production!** ðŸŽ‰
